import { NextRequest, NextResponse } from 'next/server';
import { adminStorage } from '@/lib/firebase-admin';
import { v4 as uuidv4 } from 'uuid';
import { exec } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs';
import * as os from 'os';
import * as path from 'path';
import { extractPosesFromFolder, calculateBiomechanicalAngles, FramePose as PoseFrame } from '@/lib/pose-detection';
import { ai } from '@/ai/genkit';
import { z } from 'genkit';
import {
  calculateDeterministicBiomech,
  calculateShoulderHipDistance,
  BiomechDeterministicOutput,
} from '@/lib/biomechanical-analysis';
import { Timeline, Keyframe, KeyframePose } from '@/lib/timeline-types';
import { adminDb } from '@/lib/firebase-admin';
import { Keypoint } from '@/lib/pose-detection';
import { generateRuleBasedFeedback } from '@/lib/feedback-rule-based';
import { createHash } from 'crypto';
import { detectCameraOrientation, getAnalysisCapabilities } from '@/lib/camera-orientation';

const execAsync = promisify(exec);

// ============================================================================
// CONSTANTES Y L√çMITES
// ============================================================================

const MAX_VIDEO_SIZE_MB = 120;
const MAX_VIDEO_SIZE_BYTES = MAX_VIDEO_SIZE_MB * 1024 * 1024;
const PROCESSING_TIMEOUT_MS = 5 * 60 * 1000; // 5 minutos
const ENABLE_VIDEO_DESCRIPTION = process.env.ENABLE_VIDEO_DESCRIPTION !== 'false';

interface HonestyGateResult {
  efficiencyIndex: number;
  fluidityScore: number | null;
  energyLeakPct: number | null;
  analysisComplete: boolean;
  segmentsDetected: number;
  banner: string | null;
}

function applyHonestyGate(
  sequence: BiomechDeterministicOutput['sequence'],
  metrics: BiomechDeterministicOutput['metrics'],
  efficiencyIndex: number
): HonestyGateResult {
  const detectedSegments = sequence.filter(seg => seg.status !== 'no_detectado' && seg.onsetMs !== null && seg.onsetMs !== undefined).length;
  const analysisComplete = detectedSegments >= 3;

  if (!analysisComplete) {
    return {
      efficiencyIndex: Math.min(efficiencyIndex, 40),
      fluidityScore: null,
      energyLeakPct: null,
      analysisComplete: false,
      segmentsDetected: detectedSegments,
      banner: 'An√°lisis incompleto: datos insuficientes para cadena cin√©tica.',
    };
  }

  return {
    efficiencyIndex,
    fluidityScore: metrics.fluidityScore,
    energyLeakPct: metrics.energyLeakPct,
    analysisComplete: true,
    segmentsDetected: detectedSegments,
    banner: null,
  };
}

// ============================================================================
// SCHEMAS PARA LLM (solo coaching, no n√∫meros)
// ============================================================================

const LlmCoachingInputSchema = z.object({
  videoUrl: z.string().describe('URL del video de tiro de baloncesto'),
  biomech: z.object({
    efficiencyIndex: z.number().describe('√çndice de eficiencia de transferencia energ√©tica (0-100)'),
    sequence: z.array(z.object({
      segment: z.string().describe('Segmento corporal: piernas, cadera, tronco, brazo, mu√±eca, dedos'),
      onsetMs: z.number().optional().describe('Momento de activaci√≥n en milisegundos desde el inicio (puede ser null si no detectado)'),
      order: z.number().optional().describe('Orden de activaci√≥n (1=primero, 2=segundo, etc.)'),
      status: z.string().describe('Estado: correcto, mejorable, incorrecto, no_detectado'),
      delayMs: z.number().optional().describe('Retraso en milisegundos respecto al orden ideal'),
      peakVelMs: z.number().optional().describe('Momento de pico de velocidad en ms'),
    })).describe('Secuencia de activaci√≥n de segmentos'),
    timing: z.object({
      setPointMs: z.number().nullable().optional().describe('Momento del set-point en ms'),
      releaseMs: z.number().nullable().optional().describe('Momento de liberaci√≥n en ms'),
      releaseVsLegsMs: z.number().nullable().optional().describe('Diferencia entre release y t0 en ms'),
    }).describe('An√°lisis de timing'),
    metrics: z.object({
      fluidityScore: z.number().describe('Puntuaci√≥n de fluidez (0-100)'),
      energyLeakPct: z.number().describe('Porcentaje de p√©rdidas de energ√≠a'),
      setPointScore: z.number().describe('Puntuaci√≥n del set-point (0-100)'),
      sequenceDelayMs: z.number().describe('Retraso total en la secuencia en ms'),
    }).describe('M√©tricas biomec√°nicas'),
    formattedData: z.string().optional().describe('Datos formateados como string legible para el prompt'),
    jsonData: z.string().optional().describe('Datos en formato JSON serializado para el prompt'),
  }).describe('Resultados deterministas del an√°lisis biomec√°nico'),
});

const LlmCoachingOutputSchema = z.object({
  feedback: z.object({
    errors: z.array(z.string()).describe('Errores detectados en lenguaje natural'),
    recommendations: z.array(z.string()).describe('Recomendaciones espec√≠ficas'),
    strengths: z.array(z.string()).describe('Fortalezas identificadas'),
    coachMessages: z.array(z.string()).describe('Mensajes de coaching listos para UI'),
  }).refine(
    (fb) => fb.errors.length + fb.recommendations.length + fb.strengths.length + fb.coachMessages.length >= 1,
    {
      message: 'Debe haber al menos un √≠tem en feedback (errors, recommendations, strengths o coachMessages)',
    }
  ),
  labels: z.array(z.string()).optional().describe('Tags para UI'),
});

// Schema para descripci√≥n visual del video
const VideoDescriptionInputSchema = z.object({
  videoUrl: z.string().describe('URL del video de tiro de baloncesto'),
});

const VideoDescriptionOutputSchema = z.object({
  description: z.string().describe('Descripci√≥n detallada de lo que se ve en el video - SOLO lo que est√° realmente visible'),
  details: z.object({
    aroVisible: z.boolean().describe('Si se ve el aro/canasta - false si NO est√° visible en el video'),
    colorRemera: z.string().optional().describe('Color EXACTO de la remera/camiseta - usar "no visible" si no se puede determinar'),
    colorPantalon: z.string().optional().describe('Color EXACTO del pantal√≥n - usar "no visible" si no se puede determinar'),
    entorno: z.string().describe('Tipo de entorno (gimnasio, cancha exterior, otro, indeterminado)'),
    iluminacion: z.string().optional().describe('Tipo de iluminaci√≥n - usar "no se puede determinar" si no est√° claro'),
    calidadVideo: z.string().optional().describe('Calidad del video - usar "no se puede determinar" si no est√° claro'),
    otrosDetalles: z.string().optional().describe('Otros detalles visuales relevantes que REALMENTE ves'),
  }),
  isRealVideo: z.boolean().describe('Confirma que es un video real, no simulado'),
});

// Prompt especializado SOLO para coaching (no inventa n√∫meros)
const biomechanicalCoachingPrompt = ai.definePrompt({
  name: 'biomechanicalCoachingPrompt',
  input: { schema: LlmCoachingInputSchema },
  output: { schema: LlmCoachingOutputSchema },
  prompt: `Eres un entrenador experto en biomec√°nica deportiva especializado en tiros de baloncesto.

üéØ TU TAREA:
Traducir los resultados t√©cnicos del an√°lisis biomec√°nico a mensajes de coaching claros y espec√≠ficos.

‚ö†Ô∏è REGLA CR√çTICA:
NO INVENTES N√öMEROS. Los datos biomec√°nicos ya fueron calculados de forma determinista.
Tu trabajo es INTERPRETAR y EXPLICAR estos datos en lenguaje de coaching.

‚ö†Ô∏è REGLA CR√çTICA: NO INVENTES N√öMEROS. Usa EXCLUSIVAMENTE los valores del JSON estructurado.

DATOS BIOMEC√ÅNICOS EN FORMATO JSON (FUENTE PRIMARIA - USA ESTOS N√öMEROS):
{{biomech.jsonData}}

DATOS FORMATADOS (SOLO COMO CONTEXTO LEGIBLE):
{{biomech.formattedData}}

INSTRUCCIONES DE USO:
- Lee los n√∫meros del JSON estructurado arriba (jsonData)
- Usa formattedData solo como ayuda para entender el contexto
- NO recalcules tiempos ni m√©tricas - usa los valores exactos del JSON

       AN√ÅLISIS DE LOS DATOS:

       ‚ö†Ô∏è REGLA CR√çTICA: HONESTIDAD CON DATOS FALTANTES
       - Si un segmento tiene "status: no_detectado", NO asumas que est√° correcto
       - Si MUCHOS segmentos son "no_detectado", el an√°lisis es PARCIAL
       - NO digas "secuencia correcta" si no se detectaron la mayor√≠a de segmentos
       - NO digas "excelente transferencia" si faltan datos cr√≠ticos

       1. SECUENCIA DE ACTIVACI√ìN:
          - PRIMERO: Cuenta cu√°ntos segmentos tienen "status: no_detectado"
          - Si 3 o m√°s segmentos son "no_detectado" ‚Üí el an√°lisis es PARCIAL
          - Si el an√°lisis es parcial, di expl√≠citamente: "An√°lisis limitado por falta de detecci√≥n"
          - Revisa el orden de activaci√≥n SOLO de los segmentos detectados (piernas ‚Üí cadera ‚Üí tronco ‚Üí brazo ‚Üí mu√±eca)
          - Si hay "delayMs" grande o "status: incorrecto", explica el problema
          - Si "brazo" tiene order < "cadera" o "tronco", indica "brazos anticipados"
          - Si un segmento es "no_detectado", menciona que NO se pudo evaluar ese segmento

       2. TIMING:
          - Si "releaseVsLegsMs" > 600-700ms, indica "liberaci√≥n tard√≠a"
          - Si "setPointMs" est√° muy lejos de t0+400ms, indica problema de set-point
          - Si setPointMs o releaseMs son null/undefined, indica "no detectado" en lugar de asumir

       3. M√âTRICAS:
          - "fluidityScore" bajo ‚Üí movimiento brusco
          - "energyLeakPct" alto ‚Üí p√©rdidas de energ√≠a
          - "sequenceDelayMs" alto ‚Üí retrasos en la cadena
          - Si solo se detect√≥ 1 segmento (piernas), las m√©tricas pueden ser poco confiables

       4. ERRORES ESPEC√çFICOS A DETECTAR:
          - "Brazos anticipados": Si brazo se activa antes de cadera/tronco (solo si est√°n detectados)
          - "Liberaci√≥n tard√≠a": Si releaseVsLegsMs > 700ms (solo si est√° detectado)
          - "Falta de cadera": Si cadera tiene "no_detectado" ‚Üí menciona que no se detect√≥ activaci√≥n de cadera
          - "Falta de tronco": Si tronco tiene "no_detectado" ‚Üí menciona que no se detect√≥ activaci√≥n de tronco
          - "Falta de brazo": Si brazo tiene "no_detectado" ‚Üí menciona que no se detect√≥ activaci√≥n de brazo
          - "Set-point incorrecto": Si setPointScore < 60 (solo si setPointMs est√° detectado)
          - "Movimiento brusco": Si fluidityScore < 60
          - "Fugas de energ√≠a": Si energyLeakPct > 35%
          - "An√°lisis limitado": Si 3+ segmentos son "no_detectado" ‚Üí menciona que el an√°lisis es parcial

FORMATO DE RESPUESTA:
{
  "feedback": {
    "errors": [
      "Tus brazos se adelantan. Primero genera impulso desde las piernas.",
      "Soltaste el bal√≥n tarde, despu√©s de completar la extensi√≥n."
    ],
    "recommendations": [
      "Inicia el movimiento desde las piernas antes de elevar los brazos",
      "Solt√° el bal√≥n antes, acompa√±ando la extensi√≥n final, no despu√©s"
    ],
    "strengths": [
      "Secuencia proximal ‚Üí distal correcta",
      "Timing √≥ptimo de liberaci√≥n"
    ],
    "coachMessages": [
      "Tus brazos se adelantan. Primero genera impulso desde las piernas.",
      "Necesitas mayor participaci√≥n de la cadera para transferir potencia.",
      "Elev√° el punto de carga para optimizar la trayectoria y la transferencia."
    ]
  },
  "labels": ["brazos_anticipados", "liberacion_tardia"]
}

VIDEO: {{videoUrl}}

       INSTRUCCIONES IMPORTANTES:
       1. REGLA M√çNIMA: Debes generar AL MENOS 1 mensaje en alguna categor√≠a (errors, recommendations, strengths o coachMessages)
       2. HONESTIDAD CON DATOS FALTANTES:
          - Si 3+ segmentos son "no_detectado", NO digas "secuencia correcta" o "excelente transferencia"
          - Si solo se detect√≥ "piernas", di expl√≠citamente que el an√°lisis es PARCIAL
          - Menciona en "errors" o "recommendations" que faltan datos para an√°lisis completo
       3. Si alguna lista resultar√≠a vac√≠a, agrega al menos 1 recomendaci√≥n basada en biomech.sequence y biomech.timing
       4. Si no hay errores obvios PERO faltan datos, identifica que el an√°lisis es limitado en "recommendations"
       5. Si hay aspectos positivos SOLO en segmentos detectados, incl√∫yelos en "strengths" (pero s√© honesto)
       6. Los "coachMessages" deben ser mensajes directos y espec√≠ficos para el jugador
          - Si faltan datos, menciona que el an√°lisis es parcial
       7. Los "labels" deben ser tags t√©cnicos como "brazos_anticipados", "liberacion_tardia", "analisis_parcial", etc.
       8. USA LOS N√öMEROS EXACTOS del JSON - no inventes valores, no recalcules
       9. NO asumas que algo est√° correcto si no se detect√≥ - s√© conservador

EJEMPLOS DE AN√ÅLISIS:
- Si biomech.sequence muestra brazo con order < cadera/tronco ‚Üí "brazos_anticipados"
- Si biomech.timing.releaseVsLegsMs > 700 ‚Üí "liberacion_tardia"
- Si biomech.metrics.setPointScore < 60 ‚Üí "set_point_incorrecto"
- Si biomech.metrics.fluidityScore < 60 ‚Üí "movimiento_brusco"
- Si biomech.metrics.energyLeakPct > 35 ‚Üí "fugas_energia"

Analiza los datos biomec√°nicos y genera feedback de coaching en formato JSON. SIEMPRE retorna arrays con contenido, nunca arrays vac√≠os.`
});

// Prompt para descripci√≥n visual del video (verificaci√≥n)
const videoDescriptionPrompt = ai.definePrompt({
  name: 'videoDescriptionPrompt',
  input: { schema: VideoDescriptionInputSchema },
  output: { schema: VideoDescriptionOutputSchema },
  prompt: `Eres un analista de video deportivo. Tu tarea es DESCRIBIR EXACTAMENTE lo que ves en este video de tiro de baloncesto.

üö®üö®üö® REGLAS CR√çTICAS - NO INVENTAR üö®üö®üö®
1. Describe SOLO lo que REALMENTE VES en el video
2. Si NO est√°s 100% seguro, di "no visible" o "no se puede determinar"
3. NO asumas colores bas√°ndote en "lo t√≠pico" - describe EXACTAMENTE lo que ves
4. NO inventes detalles que no est√°n claramente visibles
5. Si el aro/canasta NO est√° visible en el frame, marca aroVisible: false
6. S√© CONSERVADOR: mejor "no visible" que inventar algo incorrecto

VIDEO: {{videoUrl}}

INSTRUCCIONES DETALLADAS:

1. OBSERVA EL VIDEO COMPLETO - Frame por frame si es necesario
   - NO hagas suposiciones basadas en "lo que suele ser"
   - Mira CADA frame para verificar qu√© est√° realmente visible

2. COLOR DE ROPA - S√© MUY ESPEC√çFICO:
   - Observa el color REAL de la remera/camiseta que ves
   - Observa el color REAL del pantal√≥n/short que ves
   - Si el color es oscuro y no puedes distinguir si es azul, negro, gris oscuro ‚Üí di "color oscuro" o "no visible claramente"
   - Si el color es claro y no puedes distinguir ‚Üí di "color claro" o "no visible claramente"
   - NO inventes colores est√°ndar (blanco, negro) si no los ves claramente
   - Si ves un color espec√≠fico, di el color EXACTO (ej: "azul marino", "azul claro", "negro")

3. ARO/CANASTA:
   - Busca el aro/canasta en TODOS los frames
   - Si NO lo ves en ning√∫n frame, marca aroVisible: false
   - Si solo ves una parte (tablero pero no aro), di "parcialmente visible" en otrosDetalles
   - NO asumas que el aro est√° ah√≠ solo porque es un video de baloncesto

4. ENTORNO:
   - Observa el fondo, las paredes, el piso
   - S√© espec√≠fico: "gimnasio con paredes azules", "cancha exterior", etc.
   - Si no puedes determinar claramente ‚Üí di "indeterminado"

5. ILUMINACI√ìN Y CALIDAD:
   - Solo describe si puedes verlo claramente
   - Si no puedes determinar ‚Üí di "no se puede determinar"

6. DESCRIPCI√ìN NARRATIVA:
   - Describe SOLO lo que REALMENTE VES
   - NO uses frases como "claramente visible" si no est√°s seguro
   - Si algo no est√° visible, dilo expl√≠citamente

EJEMPLOS DE LO QUE NO DEBES HACER:
‚ùå "camiseta blanca" si el video es oscuro y no puedes ver el color claramente
‚ùå "aro claramente visible" si el aro no aparece en el video
‚ùå "pantalones negros" si solo ves una silueta oscura
‚ùå Inventar detalles del entorno si no los ves

EJEMPLOS DE LO QUE S√ç DEBES HACER:
‚úÖ "remera azul" solo si VES que es azul claramente
‚úÖ "aroVisible: false" si NO aparece el aro en el video
‚úÖ "color oscuro (no se puede determinar si azul o negro)" si no est√°s seguro
‚úÖ "no visible" si no puedes ver algo claramente

FORMATO DE RESPUESTA:
{
  "description": "Descripci√≥n EXACTA de lo que ves - solo lo que est√° realmente visible",
  "details": {
    "aroVisible": false, // true SOLO si ves el aro claramente
    "colorRemera": "azul", // O "no visible" si no puedes verlo
    "colorPantalon": "azul", // O "no visible" si no puedes verlo
    "entorno": "gimnasio",
    "iluminacion": "artificial", // O "no se puede determinar"
    "calidadVideo": "buena", // O "no se puede determinar"
    "otrosDetalles": "Detalles espec√≠ficos que REALMENTE ves"
  },
  "isRealVideo": true
}

‚ö†Ô∏è √öLTIMA ADVERTENCIA:
Este es un TEST DE VERIFICACI√ìN. Si inventas detalles, el test falla.
Describe SOLO lo que REALMENTE VES en el video, sin suposiciones ni inventos.

Responde en formato JSON con la estructura especificada.`
});

// ============================================================================
// FUNCIONES DE PROCESAMIENTO
// ============================================================================

/**
 * Procesa video con FFmpeg y extrae frames
 * Retorna paths temporales para cleanup
 */
async function processVideoForAnalysis(
  videoBuffer: Buffer,
  videoId: string,
  tmpDir: string
): Promise<{
  processedVideoPath: string;
  framesDir: string;
  thumbsDir: string;
  videoUrl: string;
  fps: number;
}> {
  const tempVideoPath = path.join(tmpDir, `temp_${videoId}.mp4`);
  const tempProcessedPath = path.join(tmpDir, `processed_${videoId}.mp4`);
  const framesDir = path.join(tmpDir, `frames_${videoId}`);
  
  // Guardar video original
  await fs.promises.writeFile(tempVideoPath, videoBuffer);
  console.log('üìÅ Video temporal guardado:', tempVideoPath);
  
  // Procesar video: 15s m√°ximo, 12 FPS, 1280x720
  const ffmpegCommand = `ffmpeg -i "${tempVideoPath}" -t 15 -vf "fps=12,scale=1280:-1:flags=lanczos" -c:v libx264 -preset fast -crf 28 -b:v 500k -an -movflags +faststart "${tempProcessedPath}" -y`;
  console.log('üîß Procesando video con FFmpeg...');
  await execAsync(ffmpegCommand);
  
  // Subir video procesado a Firebase
  const processedVideoId = `12fps-biomech-${uuidv4()}`;
  const processedVideoFileName = `test-videos/${processedVideoId}.mp4`;
  const processedVideoBuffer = await fs.promises.readFile(tempProcessedPath);
  
  if (!adminStorage) {
    throw new Error('Firebase Storage no est√° inicializado');
  }
  
  const videoRef = adminStorage.bucket().file(processedVideoFileName);
  await videoRef.save(processedVideoBuffer, {
    metadata: {
      contentType: 'video/mp4',
      metadata: {
        originalName: `biomech_${videoId}`,
        uploadedAt: new Date().toISOString(),
        fps: 12,
        resolution: '1280x720'
      }
    }
  });
  
  const videoUrl = `https://storage.googleapis.com/shotanalisys.firebasestorage.app/${processedVideoFileName}`;
  console.log('‚úÖ Video subido:', videoUrl);
  
  // Extraer frames: 15 FPS en ventana de shot (0-2s) para mejor detecci√≥n biomec√°nica
  // Esta es la ventana cr√≠tica donde ocurre la transferencia energ√©tica
  await fs.promises.mkdir(framesDir, { recursive: true });
  
  // Extraer ventana de shot (0-2s) a 15 FPS para mejor resoluci√≥n temporal
  // Esta es la ventana cr√≠tica para detectar la cadena cin√©tica
  const shotWindowCommand = `ffmpeg -i "${tempProcessedPath}" -t 2 -vf "fps=15,scale=640:-1:flags=lanczos" -q:v 4 "${framesDir}/frame_%05d.jpg" -y`;
  console.log('üîß Extrayendo ventana de shot (0-2s) a 15 FPS para an√°lisis biomec√°nico...');
  await execAsync(shotWindowCommand);
  
  // Contar frames extra√≠dos para calcular FPS real
  const frameFiles = await fs.promises.readdir(framesDir);
  const frameCount = frameFiles.filter(f => f.endsWith('.jpg')).length;
  const actualFps = frameCount >= 30 ? 15 : 8; // Si hay 30+ frames en 2s, es 15 FPS
  console.log(`üìä Frames extra√≠dos: ${frameCount}, FPS estimado: ${actualFps}`);
  
  // Extraer miniaturas para timeline: 4 FPS (cada 250ms), m√°s livianas
  const thumbsDir = path.join(tmpDir, `thumbs_${videoId}`);
  await fs.promises.mkdir(thumbsDir, { recursive: true });
  const extractThumbsCommand = `ffmpeg -i "${tempProcessedPath}" -vf "fps=4,scale=320:-1:flags=lanczos" -q:v 6 "${thumbsDir}/thumb_%05d.jpg" -y`;
  console.log('üîß Extrayendo miniaturas para timeline (4 FPS)...');
  await execAsync(extractThumbsCommand);
  
  // NO limpiar tempProcessedPath todav√≠a - se necesita para generar keyframes
  // Se limpiar√° despu√©s en el finally
  
  return {
    processedVideoPath: tempVideoPath,
    framesDir,
    thumbsDir,
    videoUrl,
    fps: actualFps, // FPS real basado en frames extra√≠dos (15 FPS en ventana de shot)
  };
}

/**
 * Realiza pose detection y c√°lculo de √°ngulos
 */
async function performPoseAnalysis(
  framesDir: string,
  fps: number
): Promise<{
  poseData: any;
  angles: Array<{tMs: number, elbowR?: number, kneeR?: number, hip?: number, wrist?: number}>;
  frames: PoseFrame[];
  shoulderHipDist: number;
}> {
  console.log('ü§ñ Iniciando pose detection...');
  
  const poseData = await extractPosesFromFolder(framesDir, fps);
  console.log(`‚úÖ Pose detection: ${poseData.frames.length} frames`);
  
  const angles = calculateBiomechanicalAngles(poseData.frames);
  console.log(`‚úÖ √Ångulos calculados: ${angles.length} muestras`);
  
  const shoulderHipDist = calculateShoulderHipDistance(poseData.frames);
  console.log(`‚úÖ Distancia hombro-cadera promedio: ${shoulderHipDist.toFixed(3)}`);
  
  return {
    poseData,
    angles,
    frames: poseData.frames,
    shoulderHipDist,
  };
}

/**
 * Extrae pose data de un frame cercano a un timestamp espec√≠fico
 */
function getPoseForTime(
  tMs: number,
  frames: PoseFrame[],
  tolerance: number = 100
): PoseFrame | null {
  // Buscar frame m√°s cercano al timestamp
  let closestFrame: PoseFrame | null = null;
  let minDiff = Infinity;
  
  for (const frame of frames) {
    const diff = Math.abs(frame.tMs - tMs);
    if (diff < minDiff && diff <= tolerance) {
      minDiff = diff;
      closestFrame = frame;
    }
  }
  
  return closestFrame;
}

/**
 * Convierte FramePose a KeyframePose con anclajes pre-calculados
 */
function framePoseToKeyframePose(frame: PoseFrame): KeyframePose {
  const anchors: KeyframePose['anchors'] = {};
  
  // Buscar keypoints espec√≠ficos y crear anclajes
  for (const kp of frame.keypoints) {
    if (kp.name === 'right_elbow') {
      anchors.elbow = { x: kp.x, y: kp.y };
    } else if (kp.name === 'right_hip') {
      anchors.hip = { x: kp.x, y: kp.y };
    } else if (kp.name === 'right_wrist') {
      anchors.wrist = { x: kp.x, y: kp.y };
    } else if (kp.name === 'right_knee') {
      anchors.knee = { x: kp.x, y: kp.y };
    } else if (kp.name === 'right_shoulder') {
      anchors.shoulder = { x: kp.x, y: kp.y };
    }
  }
  
  return {
    keypoints: frame.keypoints,
    anchors: Object.keys(anchors).length > 0 ? anchors : undefined,
  };
}

/**
 * Genera keyframes autom√°ticos basados en eventos biomec√°nicos
 */
async function generateAutoKeyframes(
  biomechOutput: BiomechDeterministicOutput,
  thumbsDir: string,
  videoId: string,
  fps: number,
  poseFrames?: PoseFrame[]
): Promise<Keyframe[]> {
  const keyframes: Keyframe[] = [];
  
  // Leer miniaturas disponibles
  const thumbFiles = await fs.promises.readdir(thumbsDir);
  const sortedThumbs = thumbFiles
    .filter(f => f.endsWith('.jpg'))
    .sort();
  
  // Funci√≥n para obtener miniatura m√°s cercana a un tMs
  const getThumbForTime = (tMs: number): string => {
    const frameIndex = Math.round((tMs / 1000) * 4); // 4 FPS para miniaturas
    const thumbFile = sortedThumbs[frameIndex] || sortedThumbs[sortedThumbs.length - 1];
    if (!thumbFile) return '';
    
    // Retornar nombre de archivo (se usar√° para subir despu√©s)
    const thumbFileName = `biomech-thumbs/${videoId}/${thumbFile}`;
    return thumbFileName;
  };
  
  // Funci√≥n helper para crear keyframe con pose si est√° disponible
  const createKeyframe = (tMs: number, notes: any, eventType?: any): Keyframe => {
    const keyframe: Keyframe = {
      id: uuidv4(),
      tMs,
      thumbUrl: getThumbForTime(tMs),
      notes,
      eventType,
    };
    
    // Agregar pose data si est√° disponible
    if (poseFrames && poseFrames.length > 0) {
      const poseFrame = getPoseForTime(tMs, poseFrames, 150); // 150ms de tolerancia
      if (poseFrame) {
        keyframe.pose = framePoseToKeyframePose(poseFrame);
      }
    }
    
    return keyframe;
  };
  
         // Keyframe 1: t0_start (inicio de extensi√≥n)
         const t0Segment = biomechOutput.sequence.find(s => s.segment === 'piernas');
         const t0Ms = (t0Segment?.onsetMs !== null && t0Segment?.onsetMs !== undefined) ? t0Segment.onsetMs : 0;
         if (t0Ms >= 0 && t0Ms < 15000) { // Validar que est√© dentro del rango del video
    keyframes.push(createKeyframe(
      t0Ms,
      [{
        id: uuidv4(),
        author: 'system',
        text: `Inicio de extensi√≥n de piernas (t0)`,
        tags: ['t0', 'piernas'],
        createdAt: new Date().toISOString(),
        anchor: 'knee',
      }],
      't0_start'
    ));
  }
  
  // Keyframe 2: Set-point
  if (biomechOutput.timing.setPointMs && biomechOutput.timing.setPointMs >= 0 && biomechOutput.timing.setPointMs < 15000) {
    keyframes.push(createKeyframe(
      biomechOutput.timing.setPointMs,
      [{
        id: uuidv4(),
        author: 'system',
        text: `Set-point detectado (score: ${biomechOutput.metrics.setPointScore}/100)`,
        tags: ['set-point'],
        createdAt: new Date().toISOString(),
        anchor: 'wrist', // Set-point t√≠picamente cerca de la mu√±eca
      }],
      'set_point'
    ));
  }
  
  // Keyframe 3: Release
  if (biomechOutput.timing.releaseMs && biomechOutput.timing.releaseMs >= 0 && biomechOutput.timing.releaseMs < 15000) {
    const releaseDelay = biomechOutput.timing.releaseVsLegsMs || 0;
    keyframes.push(createKeyframe(
      biomechOutput.timing.releaseMs,
      [{
        id: uuidv4(),
        author: 'system',
        text: `Release estimado (${releaseDelay}ms despu√©s de t0)`,
        tags: ['release'],
        createdAt: new Date().toISOString(),
        anchor: 'wrist',
      }],
      'release'
    ));
  }
  
  // Mapeo de segmentos a anclajes
  const segmentToAnchor: Record<string, 'elbow' | 'hip' | 'wrist' | 'knee' | 'shoulder' | 'none'> = {
    'cadera': 'hip',
    'tronco': 'hip',
    'brazo': 'elbow',
    'mu√±eca': 'wrist',
    'dedos': 'wrist',
    'piernas': 'knee',
  };
  
         // Keyframes para onsets de segmentos
         for (const segment of biomechOutput.sequence) {
           // Incluir todos los segmentos excepto dedos (que es muy dif√≠cil de detectar)
           if (segment.segment !== 'dedos' && 
               segment.onsetMs !== null && 
               segment.onsetMs !== undefined && 
               segment.onsetMs >= 0 && 
               segment.onsetMs < 15000) {
             const existing = keyframes.find(kf => Math.abs(kf.tMs - segment.onsetMs!) < 50);
      if (!existing && segment.onsetMs !== null && segment.onsetMs !== undefined) {
        keyframes.push(createKeyframe(
          segment.onsetMs,
          [{
            id: uuidv4(),
            author: 'system',
            text: `Onset de ${segment.segment} (${segment.status})`,
            tags: [segment.segment, 'onset'],
            createdAt: new Date().toISOString(),
            anchor: segmentToAnchor[segment.segment] || 'none',
          }],
          `onset_${segment.segment}` as any
        ));
      }
    }
  }
  
  // Keyframe para pico de velocidad (si hay)
  for (const segment of biomechOutput.sequence) {
    if (segment.peakVelMs && segment.segment !== 'piernas') {
      const existing = keyframes.find(kf => Math.abs(kf.tMs - segment.peakVelMs!) < 50);
      if (!existing) {
        keyframes.push(createKeyframe(
          segment.peakVelMs,
          [{
            id: uuidv4(),
            author: 'system',
            text: `Pico de velocidad en ${segment.segment}`,
            tags: [segment.segment, 'peak_velocity'],
            createdAt: new Date().toISOString(),
            anchor: segmentToAnchor[segment.segment] || 'none',
          }],
          'peak_velocity'
        ));
      }
    }
  }
  
  // Ordenar por tMs
  keyframes.sort((a, b) => a.tMs - b.tMs);
  
  return keyframes;
}

/**
 * Sube miniaturas a Firebase Storage y actualiza URLs
 */
async function uploadThumbnails(
  keyframes: Keyframe[],
  thumbsDir: string,
  videoId: string
): Promise<Keyframe[]> {
  if (!adminStorage) {
    console.warn('‚ö†Ô∏è Firebase Storage no disponible, saltando upload de miniaturas');
    return keyframes;
  }
  
  const updatedKeyframes = await Promise.all(
    keyframes.map(async (kf) => {
      if (!kf.thumbUrl || !kf.thumbUrl.includes('/')) {
        return kf;
      }
      
      const thumbFileName = kf.thumbUrl;
      const thumbBasename = path.basename(thumbFileName);
      const thumbPath = path.join(thumbsDir, thumbBasename);
      
      try {
        // Verificar que el archivo existe
        await fs.promises.access(thumbPath);
        const thumbBuffer = await fs.promises.readFile(thumbPath);
        if (!adminStorage) return kf;
        const thumbRef = adminStorage.bucket().file(thumbFileName);
        
        await thumbRef.save(thumbBuffer, {
          metadata: {
            contentType: 'image/jpeg',
            metadata: {
              analysisId: videoId,
              tMs: kf.tMs.toString(),
            }
          }
        });
        
        // Generar URL p√∫blica
        const [url] = await thumbRef.getSignedUrl({
          action: 'read',
          expires: '03-01-2500', // URL de larga duraci√≥n
        });
        
        return {
          ...kf,
          thumbUrl: url,
        };
      } catch (error) {
        console.warn(`‚ö†Ô∏è Error subiendo miniatura ${thumbFileName}:`, error);
      }
      
      return kf;
    })
  );
  
  return updatedKeyframes;
}

// ============================================================================
// ENDPOINT PRINCIPAL
// ============================================================================

export async function POST(request: NextRequest) {
  const analysisId = `biomech-${uuidv4()}`;
  const tmpDir = path.join(os.tmpdir(), analysisId);
  let cleanupPaths: string[] = [tmpDir];
  
  const startTime = Date.now();
  
  try {
    // Validaci√≥n de Content-Type
    const contentType = request.headers.get('content-type');
    if (!contentType || !contentType.includes('multipart/form-data')) {
      return NextResponse.json(
        { error: 'Content-Type debe ser multipart/form-data' },
        { status: 400 }
      );
    }
    
    const formData = await request.formData();
    const videoFile = formData.get('video') as File;
    const cameraHintRaw = (formData.get('camera_hint') as string | null)?.toLowerCase();
    const cameraHint = cameraHintRaw === 'lateral' || cameraHintRaw === 'frontal' ? cameraHintRaw : undefined;
    
    if (!videoFile) {
      return NextResponse.json(
        { error: 'No se proporcion√≥ archivo de video' },
        { status: 400 }
      );
    }
    
    // Validaci√≥n de tama√±o
    if (videoFile.size > MAX_VIDEO_SIZE_BYTES) {
      return NextResponse.json(
        { 
          error: `Video demasiado grande. M√°ximo: ${MAX_VIDEO_SIZE_MB}MB`,
          size: videoFile.size,
          maxSize: MAX_VIDEO_SIZE_BYTES
        },
        { status: 400 }
      );
    }
    
    console.log(`üìä [${analysisId}] Video recibido:`, {
      name: videoFile.name,
      size: `${(videoFile.size / 1024 / 1024).toFixed(2)}MB`,
      type: videoFile.type
    });
    
    const videoBuffer = Buffer.from(await videoFile.arrayBuffer());
    
    // Crear directorio temporal
    await fs.promises.mkdir(tmpDir, { recursive: true });
    
    // 1. PROCESAR VIDEO
    const videoProcessingStart = Date.now();
    const { processedVideoPath, framesDir, thumbsDir, videoUrl, fps } = await processVideoForAnalysis(
      videoBuffer,
      analysisId,
      tmpDir
    );
    cleanupPaths.push(processedVideoPath, framesDir, thumbsDir);
    
    // Guardar processedVideoPath para uso en descripci√≥n visual
    const videoProcessedPath = processedVideoPath;
    const videoProcessingTime = Date.now() - videoProcessingStart;
    console.log(`‚è±Ô∏è [${analysisId}] Procesamiento de video: ${videoProcessingTime}ms`);
    
    // 2. POSE DETECTION Y √ÅNGULOS
    const poseStart = Date.now();
    let poseAnalysis: {
      poseData: any;
      angles: Array<{tMs: number, elbowR?: number, kneeR?: number, hip?: number, wrist?: number}>;
      frames: PoseFrame[];
      shoulderHipDist: number;
    } | null = null;
    let poseTime = 0;
    
    try {
      poseAnalysis = await performPoseAnalysis(framesDir, fps);
      poseTime = Date.now() - poseStart;
      console.log(`‚è±Ô∏è [${analysisId}] Pose detection: ${poseTime}ms`);

      // Detectar orientaci√≥n de c√°mara
      if (poseAnalysis && poseAnalysis.frames.length > 0) {
        const framesWithPose = poseAnalysis.frames.filter(frame =>
          frame.keypoints?.some(kp => (kp.score ?? 0) >= 0.3)
        ).length;
        const poseCoverage = poseAnalysis.frames.length > 0
          ? ((framesWithPose / poseAnalysis.frames.length) * 100).toFixed(1)
          : '0.0';
        console.log(`ü§ñ [${analysisId}] Landmarks v√°lidos en ${framesWithPose}/${poseAnalysis.frames.length} frames (${poseCoverage}%)`);

        const cameraOrientation = detectCameraOrientation(poseAnalysis.frames, {
          hint: cameraHint,
        });
        const capabilities = getAnalysisCapabilities(cameraOrientation.orientation);
        
        console.log(`üìπ [${analysisId}] Orientaci√≥n de c√°mara:`, {
          orientation: cameraOrientation.orientation,
          confidence: cameraOrientation.confidence,
          reasoning: cameraOrientation.reasoning,
          metrics: cameraOrientation.metrics,
          capabilities: {
            canAnalyzeSequence: capabilities.canAnalyzeSequence,
            canAnalyzeSetPoint: capabilities.canAnalyzeSetPoint,
            canAnalyzeRelease: capabilities.canAnalyzeRelease,
          },
        });
        
        // Guardar para respuesta
        (poseAnalysis as any).cameraOrientation = cameraOrientation;
        (poseAnalysis as any).capabilities = capabilities;
      }
    } catch (poseError: any) {
      poseTime = Date.now() - poseStart;
      console.warn(`‚ö†Ô∏è [${analysisId}] Error en pose detection (${poseTime}ms):`, poseError.message);
      // Continuar sin pose detection (fallback)
    }
    
    // 3. AN√ÅLISIS BIOMEC√ÅNICO DETERMINISTA
    console.log(`üìê [${analysisId}] Calculando an√°lisis biomec√°nico determinista...`);
    const biomechStart = Date.now();
    
    let biomechOutput: BiomechDeterministicOutput;
    let honesty: HonestyGateResult | null = null;
    
    if (poseAnalysis && poseAnalysis.angles.length >= 5) {
      // Funci√≥n de logging para debugging
      const debugLog = (msg: string, data?: any) => {
        console.log(`üîç [${analysisId}] ${msg}`, data || '');
      };
      
      biomechOutput = calculateDeterministicBiomech(
        poseAnalysis.angles,
        poseAnalysis.frames,
        fps,
        debugLog
      );
      console.log(`‚úÖ [${analysisId}] An√°lisis determinista completado:`, {
        efficiencyIndex: biomechOutput.efficiencyIndex,
        sequenceLength: biomechOutput.sequence.length,
        sequenceSegments: biomechOutput.sequence.map(s => s.segment),
        setPointMs: biomechOutput.timing.setPointMs,
        releaseMs: biomechOutput.timing.releaseMs,
        fluidityScore: biomechOutput.metrics.fluidityScore
      });
    } else {
      // Fallback: valores por defecto si no hay datos de pose
      console.warn(`‚ö†Ô∏è [${analysisId}] Sin datos de pose, usando valores por defecto`);
      biomechOutput = {
        efficiencyIndex: 50,
        sequence: [
          { segment: 'piernas', onsetMs: 0, order: 1, status: 'mejorable' },
          { segment: 'cadera', onsetMs: 150, order: 2, status: 'mejorable' },
          { segment: 'brazo', onsetMs: 450, order: 4, status: 'mejorable' },
        ],
        timing: { setPointMs: 550, releaseMs: 650 },
        metrics: {
          fluidityScore: 50,
          energyLeakPct: 50,
          setPointScore: 50,
          sequenceDelayMs: 0,
        },
      };
    }
    const biomechTime = Date.now() - biomechStart;
    console.log(`‚è±Ô∏è [${analysisId}] An√°lisis biomec√°nico: ${biomechTime}ms`);

    honesty = applyHonestyGate(
      biomechOutput.sequence,
      biomechOutput.metrics,
      biomechOutput.efficiencyIndex
    );

    let analysisComplete = honesty.analysisComplete;
    let segmentsDetected = honesty.segmentsDetected;
    let effectiveEfficiencyIndex = honesty.efficiencyIndex;
    let effectiveFluidity = honesty.fluidityScore;
    let effectiveEnergy = honesty.energyLeakPct;

    console.log(`üì∏ [${analysisId}] Generando keyframes autom√°ticos...`);
    const keyframesStart = Date.now();
    let autoKeyframes: Keyframe[] = [];
    let keyframesTime = 0;

    try {
      autoKeyframes = await generateAutoKeyframes(
        biomechOutput,
        thumbsDir,
        analysisId,
        fps,
        poseAnalysis?.frames // Pasar frames de pose para anclaje
      );

      // Subir miniaturas a Firebase
      autoKeyframes = await uploadThumbnails(autoKeyframes, thumbsDir, analysisId);

      keyframesTime = Date.now() - keyframesStart;
      console.log(`‚úÖ [${analysisId}] ${autoKeyframes.length} keyframes generados (${keyframesTime}ms)`);
    } catch (keyframeError: any) {
      keyframesTime = Date.now() - keyframesStart;
      console.warn(`‚ö†Ô∏è [${analysisId}] Error generando keyframes (${keyframesTime}ms):`, keyframeError.message);
      // Continuar sin keyframes (no cr√≠tico)
    }

    // 5. DESCRIPCI√ìN VISUAL DEL VIDEO (verificaci√≥n)
    console.log(`üëÅÔ∏è [${analysisId}] Generando descripci√≥n visual del video...`);
    let videoDescription: any = null;
    let videoDescriptionTime = 0;

    if (ENABLE_VIDEO_DESCRIPTION) {
      const descriptionStartTime = Date.now();
      try {
        const descriptionResult = await videoDescriptionPrompt({ videoUrl });
        videoDescription = descriptionResult.output;
        videoDescriptionTime = Date.now() - descriptionStartTime;
        console.log(`‚úÖ [${analysisId}] Descripci√≥n visual generada (${videoDescriptionTime}ms):`, {
          aroVisible: videoDescription.details.aroVisible,
          entorno: videoDescription.details.entorno,
          isRealVideo: videoDescription.isRealVideo,
        });
      } catch (descriptionError: any) {
        videoDescriptionTime = Date.now() - descriptionStartTime;
        console.warn(`‚ö†Ô∏è [${analysisId}] Error generando descripci√≥n visual (${videoDescriptionTime}ms):`, descriptionError.message);
        console.warn(`‚ö†Ô∏è [${analysisId}] Stack:`, descriptionError.stack);

        try {
          console.log(`üîÑ [${analysisId}] Intentando descripci√≥n con Gemini directo...`);
          const processedVideoBuffer = await fs.promises.readFile(videoProcessedPath);
          const videoBase64 = processedVideoBuffer.toString('base64');

          const { GoogleGenerativeAI } = await import('@google/generative-ai');
          const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
          const model = genAI.getGenerativeModel({
            model: 'gemini-2.0-flash-exp',
            generationConfig: {
              maxOutputTokens: 1024,
              responseMimeType: 'application/json',
            }
          });

          const prompt = `Describe EXACTAMENTE lo que ves en este video de tiro de baloncesto. Responde SOLO con JSON:

{
  "description": "Descripci√≥n de 2-3 oraciones de lo que REALMENTE ves",
  "details": {
    "aroVisible": true/false,
    "colorRemera": "color EXACTO o 'no visible'",
    "colorPantalon": "color EXACTO o 'no visible'",
    "entorno": "gimnasio/cancha exterior/otro/indeterminado",
    "iluminacion": "natural/artificial/mixta/no se puede determinar",
    "calidadVideo": "excelente/buena/regular/mala/no se puede determinar",
    "otrosDetalles": "otros detalles que REALMENTE ves"
  },
  "isRealVideo": true
}`;

          const result = await model.generateContent([
            prompt,
            {
              inlineData: {
                mimeType: 'video/mp4',
                data: videoBase64
              }
            }
          ]);

          const responseText = result.response.text();
          const cleanJson = responseText.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim();
          videoDescription = JSON.parse(cleanJson);

          console.log(`‚úÖ [${analysisId}] Descripci√≥n generada con Gemini directo`);
        } catch (fallbackError: any) {
          console.warn(`‚ö†Ô∏è [${analysisId}] Fallback tambi√©n fall√≥:`, fallbackError.message);
          videoDescription = {
            description: 'No se pudo generar descripci√≥n visual del video.',
            details: {
              aroVisible: false,
              entorno: 'indeterminado',
            },
            isRealVideo: true,
            disabled: true,
          };
        }
      }
    } else {
      videoDescription = {
        description: 'Verificaci√≥n visual deshabilitada temporalmente.',
        details: {
          aroVisible: false,
          entorno: 'indeterminado',
          iluminacion: 'no se puede determinar',
          calidadVideo: 'no se puede determinar',
          otrosDetalles: 'Verificaci√≥n pendiente: reactivar cuando est√© disponible la clave de Gemini.',
        },
        isRealVideo: true,
        disabled: true,
      };
      console.log(`‚ÑπÔ∏è [${analysisId}] Verificaci√≥n visual deshabilitada por configuraci√≥n.`);
    }
    
    // Serializar JSON para el prompt (fuente primaria)
    const biomechJsonString = JSON.stringify({
      efficiencyIndex: effectiveEfficiencyIndex,
      sequence: biomechOutput.sequence,
      timing: biomechOutput.timing,
      metrics: {
        ...biomechOutput.metrics,
        fluidityScore: analysisComplete ? biomechOutput.metrics.fluidityScore : null,
        energyLeakPct: analysisComplete ? biomechOutput.metrics.energyLeakPct : null,
      },
      analysisComplete,
      segmentsDetected,
    }, null, 2);
    
    // Formatear datos biomec√°nicos como string legible para el prompt (contexto)
    const biomechDataString = `
Eficiencia (gated): ${effectiveEfficiencyIndex}/100
Cobertura de segmentos: ${segmentsDetected} detectados de 6 (an√°lisis completo: ${analysisComplete ? 's√≠' : 'no'})

Secuencia de activaci√≥n:
${biomechOutput.sequence.map(s => 
  `  - ${s.segment}: activaci√≥n a ${s.onsetMs !== null && s.onsetMs !== undefined ? `${s.onsetMs}ms` : 'N/A'}, orden ${s.order || 'N/A'}, estado: ${s.status}${s.delayMs ? `, retraso: ${s.delayMs}ms` : ''}${s.peakVelMs ? `, pico de velocidad: ${s.peakVelMs}ms` : ''}`
).join('\n')}

Timing:
  - Set-point: ${biomechOutput.timing.setPointMs || 'No detectado'}ms (score: ${biomechOutput.metrics.setPointScore}/100)
  - Release: ${biomechOutput.timing.releaseMs || 'No detectado'}ms (${biomechOutput.timing.releaseVsLegsMs || 'N/A'}ms despu√©s de t0)

M√©tricas:
  - Fluidez: ${analysisComplete && effectiveFluidity !== null ? `${effectiveFluidity}/100` : 'No se reporta (an√°lisis incompleto)'}
  - P√©rdidas de energ√≠a: ${analysisComplete && effectiveEnergy !== null ? `${effectiveEnergy}%` : 'No se reporta (an√°lisis incompleto)'}
  - Retraso en secuencia: ${biomechOutput.metrics.sequenceDelayMs}ms
`;
    
    // Hash del input para trazabilidad
    const inputHash = createHash('md5')
      .update(JSON.stringify({ biomech: biomechOutput, videoUrl }))
      .digest('hex')
      .substring(0, 8);
    
    console.log(`üìä [${analysisId}] Datos biomec√°nicos formateados:`, {
      inputHash,
      sequenceLength: biomechOutput.sequence.length,
      jsonDataLength: biomechJsonString.length,
      formattedDataLength: biomechDataString.length,
    });
    
    // Funci√≥n helper para validar y post-procesar feedback
    const validateAndPostProcess = (output: any): any => {
      if (!output?.feedback) return null;
      
      // Post-procesamiento: normalizar y completar
      const feedback = {
        errors: Array.isArray(output.feedback.errors) ? output.feedback.errors.filter((e: string) => e?.trim()).map((e: string) => e.trim().substring(0, 500)) : [],
        recommendations: Array.isArray(output.feedback.recommendations) ? output.feedback.recommendations.filter((r: string) => r?.trim()).map((r: string) => r.trim().substring(0, 500)) : [],
        strengths: Array.isArray(output.feedback.strengths) ? output.feedback.strengths.filter((s: string) => s?.trim()).map((s: string) => s.trim().substring(0, 500)) : [],
        coachMessages: Array.isArray(output.feedback.coachMessages) ? output.feedback.coachMessages.filter((m: string) => m?.trim()).map((m: string) => m.trim().substring(0, 500)) : [],
      };
      
      // Eliminar duplicados
      feedback.errors = Array.from(new Set(feedback.errors));
      feedback.recommendations = Array.from(new Set(feedback.recommendations));
      feedback.strengths = Array.from(new Set(feedback.strengths));
      feedback.coachMessages = Array.from(new Set(feedback.coachMessages));
      
      // Validar regla m√≠nima: al menos un √≠tem
      const totalItems = feedback.errors.length + feedback.recommendations.length + feedback.strengths.length + feedback.coachMessages.length;
      if (totalItems === 0) {
        return null; // No cumple regla m√≠nima
      }
      
      return {
        feedback,
        labels: Array.isArray(output.labels) ? Array.from(new Set(output.labels.filter((l: string) => l?.trim()))) : [],
      };
    };
    
    // Funci√≥n para intentar generar feedback con reintento
    const tryGenerateFeedback = async (isRetry: boolean = false): Promise<any> => {
      // Filtrar valores null para el prompt (el LLM no necesita nulls)
      const biomechForPrompt = {
        efficiencyIndex: effectiveEfficiencyIndex,
        sequence: biomechOutput.sequence.map(s => ({
          ...s,
          onsetMs: s.onsetMs ?? undefined,
          order: s.order ?? undefined,
        })),
        timing: biomechOutput.timing,
        metrics: {
          ...biomechOutput.metrics,
          fluidityScore: analysisComplete && effectiveFluidity !== null ? effectiveFluidity : 0,
          energyLeakPct: analysisComplete && effectiveEnergy !== null ? effectiveEnergy : 0,
        },
        analysisComplete,
        segmentsDetected,
        formattedData: biomechDataString,
        jsonData: biomechJsonString,
      };
      
      const promptInput = {
        videoUrl,
        biomech: biomechForPrompt,
      };
      
      if (isRetry) {
        // Agregar instrucci√≥n de reparaci√≥n
        (promptInput as any).repairInstruction = 'Tu salida anterior no cumpli√≥ el esquema. Completa como m√≠nimo 1 recomendaci√≥n basada en la secuencia detectada. Usa exclusivamente los datos num√©ricos provistos en el JSON.';
      }
      
      const result = await biomechanicalCoachingPrompt(promptInput);
      const validated = validateAndPostProcess(result.output);
      
      if (validated) {
        // Validar con Zod
        const zodResult = LlmCoachingOutputSchema.safeParse(validated);
        if (zodResult.success) {
          return zodResult.data;
        } else {
          console.warn(`‚ö†Ô∏è [${analysisId}] Validaci√≥n Zod fall√≥:`, zodResult.error.errors);
          return null;
        }
      }
      
      return null;
    };
    
    let coachingOutput: any = null;
    let coachingStartTime = Date.now();
    
    try {
      // Primer intento
      coachingOutput = await tryGenerateFeedback(false);
      
      // Si falla validaci√≥n, reintentar una vez
      if (!coachingOutput) {
        console.warn(`‚ö†Ô∏è [${analysisId}] Primer intento fall√≥ validaci√≥n, reintentando...`);
        coachingOutput = await tryGenerateFeedback(true);
      }
      
      const coachingTime = Date.now() - coachingStartTime;
      
      if (coachingOutput) {
        console.log(`‚úÖ [${analysisId}] Feedback generado (${coachingTime}ms):`, {
          inputHash,
          errors: coachingOutput.feedback.errors.length,
          recommendations: coachingOutput.feedback.recommendations.length,
          strengths: coachingOutput.feedback.strengths.length,
          coachMessages: coachingOutput.feedback.coachMessages.length,
          labels: coachingOutput.labels?.length || 0,
        });
      } else {
        throw new Error('Validaci√≥n fall√≥ despu√©s de reintento');
      }
    } catch (coachingError: any) {
      const coachingTime = Date.now() - coachingStartTime;
      console.error(`‚ùå [${analysisId}] Error en coaching prompt (${coachingTime}ms):`, coachingError.message);
      console.log(`üîÑ [${analysisId}] Usando fallback rule-based...`);
      
      // FALLBACK: Generar feedback rule-based
      const ruleBasedFeedback = generateRuleBasedFeedback(biomechOutput);
      coachingOutput = {
        feedback: ruleBasedFeedback.feedback,
        labels: ruleBasedFeedback.labels,
        _source: 'rule-based', // Marca para logging
      };
      
      console.log(`‚úÖ [${analysisId}] Feedback rule-based generado:`, {
        inputHash,
        errors: coachingOutput.feedback.errors.length,
        recommendations: coachingOutput.feedback.recommendations.length,
        strengths: coachingOutput.feedback.strengths.length,
        coachMessages: coachingOutput.feedback.coachMessages.length,
        labels: coachingOutput.labels.length,
        source: 'rule-based',
      });
    }
    
    // GARANTIZAR: Nunca devolver feedback vac√≠o
    if (!coachingOutput || !coachingOutput.feedback || (
      coachingOutput.feedback.errors.length === 0 &&
      coachingOutput.feedback.recommendations.length === 0 &&
      coachingOutput.feedback.strengths.length === 0 &&
      coachingOutput.feedback.coachMessages.length === 0
    )) {
      console.warn(`‚ö†Ô∏è [${analysisId}] Feedback vac√≠o detectado, generando fallback rule-based...`);
      const fallbackFeedback = generateRuleBasedFeedback(biomechOutput);
      coachingOutput = {
        feedback: fallbackFeedback.feedback,
        labels: fallbackFeedback.labels,
        _source: 'rule-based-fallback',
      };
    }
    
    // GARANTIZAR: Secuencia siempre completa (6 segmentos)
    if (biomechOutput.sequence.length < 6) {
      console.warn(`‚ö†Ô∏è [${analysisId}] Secuencia incompleta (${biomechOutput.sequence.length} segmentos), aplicando backfill...`);
      const EXPECTED = ['piernas', 'cadera', 'tronco', 'brazo', 'mu√±eca', 'dedos'] as const;
      const bySeg = Object.fromEntries(biomechOutput.sequence.map(s => [s.segment, s]));
      biomechOutput.sequence = EXPECTED.map(seg => {
        const existing = bySeg[seg];
        if (existing) return existing;
        return {
          segment: seg,
          onsetMs: null,
          order: seg === 'piernas' ? 1 : seg === 'cadera' ? 2 : seg === 'tronco' ? 3 : seg === 'brazo' ? 4 : seg === 'mu√±eca' ? 5 : 6,
          status: 'no_detectado' as const,
          delayMs: undefined,
        };
      });
    }
    
    // 6. CREAR TIMELINE EN FIRESTORE
    const timeline: Timeline = {
      videoUrl,
      durationMs: 15000, // 15 segundos limitado
      fps,
      keyframes: autoKeyframes,
      analysisId,
    };
    
    try {
      if (adminDb) {
        await adminDb.collection('biomech_timelines').doc(analysisId).set({
          ...timeline,
          createdAt: new Date().toISOString(),
          updatedAt: new Date().toISOString(),
        });
        console.log(`‚úÖ [${analysisId}] Timeline guardado en Firestore`);
      } else {
        console.warn(`‚ö†Ô∏è [${analysisId}] Firestore no disponible, timeline no guardado`);
      }
    } catch (timelineError: any) {
      console.warn(`‚ö†Ô∏è [${analysisId}] Error guardando timeline:`, timelineError.message);
      // Continuar sin timeline (no cr√≠tico)
    }
    
    // 7. RESPUESTA FINAL
    const processingTime = Date.now() - startTime;
    
    // Calcular tiempos de fases
    const coachingTime = coachingOutput ? (Date.now() - coachingStartTime) : 0;
    const phaseTimes = {
      videoProcessing: videoProcessingTime,
      poseDetection: poseTime,
      biomechAnalysis: biomechTime,
      keyframes: keyframesTime,
      coaching: coachingTime,
      total: processingTime,
    };
    
    const response = {
      success: true,
      message: 'An√°lisis biomec√°nico de transferencia energ√©tica completado',
      analysisId,
      _trace: {
        inputHash,
        feedbackSource: coachingOutput._source || 'llm',
        phaseTimes,
        keyframesCount: autoKeyframes.length,
        sequenceLength: biomechOutput.sequence.length,
      },
      camera_orientation: poseAnalysis && (poseAnalysis as any).cameraOrientation ? {
        orientation: (poseAnalysis as any).cameraOrientation.orientation,
        confidence: (poseAnalysis as any).cameraOrientation.confidence,
        confidence_score: (poseAnalysis as any).cameraOrientation.confidenceScore,
        reasoning: (poseAnalysis as any).cameraOrientation.reasoning,
        capabilities: (poseAnalysis as any).capabilities,
        metrics: (poseAnalysis as any).cameraOrientation.metrics,
      } : null,
      video_description: videoDescription ? {
        description: videoDescription.description,
        details: videoDescription.details,
        isRealVideo: videoDescription.isRealVideo,
      } : null,
      // Datos deterministas (no inventados por LLM)
      efficiency_index: effectiveEfficiencyIndex,
      analysis_summary: {
        analysis_complete: analysisComplete,
        segments_detected: segmentsDetected,
        banner: honesty.banner,
      },
      activation_sequence: biomechOutput.sequence.map(s => ({
        name: s.segment,
        activation_time: s.onsetMs !== null && s.onsetMs !== undefined ? `${(s.onsetMs / 1000).toFixed(2)}s` : 'N/A',
        activation_time_ms: s.onsetMs ?? null,
        peak_velocity_ms: s.peakVelMs ?? null,
        order: s.order ?? null,
        status: s.status,
        delay_ms: s.delayMs ?? null,
      })),
      timing_analysis: {
        set_point: {
          position: biomechOutput.timing.setPointMs ? 'Detectado' : 'No detectado',
          timestamp: biomechOutput.timing.setPointMs 
            ? `${(biomechOutput.timing.setPointMs / 1000).toFixed(2)}s`
            : 'N/A',
          timestamp_ms: biomechOutput.timing.setPointMs,
          height: 'Calculado',
          status: analysisComplete
            ? (biomechOutput.metrics.setPointScore >= 80 ? 'correcto'
              : biomechOutput.metrics.setPointScore >= 60 ? 'mejorable'
              : 'incorrecto')
            : 'estimado (datos incompletos)',
        },
        release: {
          timestamp: biomechOutput.timing.releaseMs
            ? `${(biomechOutput.timing.releaseMs / 1000).toFixed(2)}s`
            : 'N/A',
          timestamp_ms: biomechOutput.timing.releaseMs,
          timing: biomechOutput.timing.releaseVsLegsMs
            ? `${biomechOutput.timing.releaseVsLegsMs}ms despu√©s de t0`
            : 'N/A',
          status: analysisComplete
            ? (biomechOutput.timing.releaseVsLegsMs 
                ? (biomechOutput.timing.releaseVsLegsMs <= 700 ? 'correcto' : 'mejorable')
                : 'mejorable')
            : 'estimado (datos incompletos)',
        },
      },
      // Feedback de coaching (generado por LLM)
      feedback: coachingOutput.feedback,
      labels: coachingOutput.labels || [],
      // M√©tricas deterministas
      metrics: {
        fluidity_score: effectiveFluidity,
        energy_loss: effectiveEnergy,
        set_point_score: biomechOutput.metrics.setPointScore,
        sequence_delay_ms: biomechOutput.metrics.sequenceDelayMs,
      },
      video_info: {
        original_name: videoFile.name,
        original_size: videoFile.size,
        duration: '15.0s (limitado)',
        fps: 12,
        resolution: '1280x720',
        video_url: videoUrl
      },
      timeline: {
        keyframes_count: autoKeyframes.length,
        timeline_id: analysisId,
        comments_api: `/api/test-biomechanical-transfer/${analysisId}/comments`,
      },
      processing_time: new Date().toISOString(),
      processing_duration_ms: processingTime,
    };
    
    // Logs de auditor√≠a mejorados
    console.log(`‚úÖ [${analysisId}] An√°lisis completado:`, {
      inputHash,
      duration: `${processingTime}ms`,
      phaseTimes,
      frames: poseAnalysis?.frames.length || 0,
      angles: poseAnalysis?.angles.length || 0,
      efficiency: effectiveEfficiencyIndex,
      keyframes: autoKeyframes.length,
      feedbackItems: {
        errors: coachingOutput.feedback.errors.length,
        recommendations: coachingOutput.feedback.recommendations.length,
        strengths: coachingOutput.feedback.strengths.length,
        coachMessages: coachingOutput.feedback.coachMessages.length,
      },
      feedbackSource: coachingOutput._source || 'llm',
    });
    
    return NextResponse.json(response);
    
  } catch (error: any) {
    const processingTime = Date.now() - startTime;
    console.error(`‚ùå [${analysisId}] Error:`, {
      message: error.message,
      duration: `${processingTime}ms`,
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    });
    
    return NextResponse.json({
      success: false,
      error: 'Error en an√°lisis biomec√°nico',
      details: error.message,
      analysisId,
      processing_duration_ms: processingTime,
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    }, { status: 500 });
    
  } finally {
    // Limpieza de archivos temporales
    console.log(`üßπ [${analysisId}] Limpiando archivos temporales...`);
    for (const cleanupPath of cleanupPaths) {
      try {
        if (await fs.promises.stat(cleanupPath).then(() => true).catch(() => false)) {
          if ((await fs.promises.stat(cleanupPath)).isDirectory()) {
            await fs.promises.rm(cleanupPath, { recursive: true, force: true });
          } else {
            await fs.promises.unlink(cleanupPath);
          }
        }
      } catch (cleanupError) {
        console.warn(`‚ö†Ô∏è [${analysisId}] Error limpiando ${cleanupPath}:`, cleanupError);
      }
    }
    console.log(`‚úÖ [${analysisId}] Limpieza completada`);
  }
}
